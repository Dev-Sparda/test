def run_pipeline(root_window):
    """
    Ejecuta todo el pipeline de generación de reportes.
    root_window: necesario para filedialog desde una app CTk.
    """
    conn = sqlite3.connect(DB_PATH)

    try:
        # 1. Cargar movimientos y unir con catálogo para obtener CLAVE_BANXICO
        df_mov = pd.read_sql("""
            SELECT 
                m.CONTRAPARTE,
                m.EMISION,
                m.TITULOS,
                m.ISIN,
                m.ENVIO_RECEPCION,
                c.CLAVE_BANXICO
            FROM MOVIMIENTOS m
            LEFT JOIN CAT_CONTRAPARTES c ON m.CONTRAPARTE = c.CONTRAPARTE
        """, conn)

        if df_mov.empty:
            messagebox.showwarning("Advertencia", "No hay movimientos cargados.")
            return

        # Asegurar que TITULOS sea numérico
        df_mov['TITULOS'] = pd.to_numeric(df_mov['TITULOS'], errors='coerce')

        # 2. Agrupar por CLAVE_BANXICO + EMISION (no por CONTRAPARTE)
        df_agrupado = df_mov.groupby(['CLAVE_BANXICO', 'EMISION'], as_index=False).agg({
            'TITULOS': 'sum',
            'ISIN': 'first',
            'ENVIO_RECEPCION': 'first'
        })

        # 3. Eliminar posiciones neteadas a cero
        df_agrupado = df_agrupado[df_agrupado['TITULOS'] != 0].copy()


import requests
from bs4 import BeautifulSoup
import time
import pandas as pd

def scrape_yahoo_finance_safe(ticker):
    """
    Ejemplo MUY básico y conservador
    """
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
    }
    
    url = f"https://finance.yahoo.com/quote/{ticker}"
    
    try:
        # Delay conservador
        time.sleep(2)
        
        response = requests.get(url, headers=headers, timeout=10)
        soup = BeautifulSoup(response.content, 'html.parser')
        
        # Extraer precio actual (ejemplo)
        price_element = soup.find('fin-streamer', {'data-field': 'regularMarketPrice'})
        price = price_element.text if price_element else "No encontrado"
        
        return {'ticker': ticker, 'price': price}
        
    except Exception as e:
        return {'ticker': ticker, 'error': str(e)}

# Uso MUY conservador
# result = scrape_yahoo_finance_safe("AAPL")
# print(result)
        if df_agrupado.empty:
            messagebox.showinfo("Información", "No hay posiciones abiertas (todo neteado a cero).")
            return

        # 4. Volver a unir con CAT_CONTRAPARTES para recuperar CONTRAPARTE
        # (por si hay más de una contraparte por CLAVE_BANXICO, tomamos la primera)
        df_final = df_agrupado.merge(
            df_mov[['CLAVE_BANXICO', 'CONTRAPARTE']].drop_duplicates(),
            on='CLAVE_BANXICO',
            how='left'
        )

        # 5. Clasificar como nacional o extranjero
        df_final['TIPO'] = df_final['EMISION'].apply(classify_emision)
        total_titulos = df_final['TITULOS'].sum()
        messagebox.showinfo("Total", f"Suma total de títulos (neto): {total_titulos:,}")

n0qQDqT6FbpjjHO9JZoDh8wssHuDwIHL
