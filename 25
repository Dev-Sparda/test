def run_pipeline(root_window):
    """
    Ejecuta todo el pipeline de generaci√≥n de reportes.
    root_window: necesario para filedialog desde una app CTk.
    """
    conn = sqlite3.connect(DB_PATH)

    try:
        # 1. Cargar movimientos y unir con cat√°logo para obtener CLAVE_BANXICO
        df_mov = pd.read_sql("""
            SELECT 
                m.CONTRAPARTE,
                m.EMISION,
                m.TITULOS,
                m.ISIN,
                m.ENVIO_RECEPCION,
                c.CLAVE_BANXICO
            FROM MOVIMIENTOS m
            LEFT JOIN CAT_CONTRAPARTES c ON m.CONTRAPARTE = c.CONTRAPARTE
        """, conn)

        if df_mov.empty:
            messagebox.showwarning("Advertencia", "No hay movimientos cargados.")
            return

        # Asegurar que TITULOS sea num√©rico
        df_mov['TITULOS'] = pd.to_numeric(df_mov['TITULOS'], errors='coerce')

        # 2. Agrupar por CLAVE_BANXICO + EMISION (no por CONTRAPARTE)
        df_agrupado = df_mov.groupby(['CLAVE_BANXICO', 'EMISION'], as_index=False).agg({
            'TITULOS': 'sum',
            'ISIN': 'first',
            'ENVIO_RECEPCION': 'first'
        })

        # 3. Eliminar posiciones neteadas a cero
        df_agrupado = df_agrupado[df_agrupado['TITULOS'] != 0].copy()



        if df_agrupado.empty:
            messagebox.showinfo("Informaci√≥n", "No hay posiciones abiertas (todo neteado a cero).")
            return

        # 4. Volver a unir con CAT_CONTRAPARTES para recuperar CONTRAPARTE
        # (por si hay m√°s de una contraparte por CLAVE_BANXICO, tomamos la primera)
        df_final = df_agrupado.merge(
            df_mov[['CLAVE_BANXICO', 'CONTRAPARTE']].drop_duplicates(),
            on='CLAVE_BANXICO',
            how='left'
        )

        # 5. Clasificar como nacional o extranjero
        df_final['TIPO'] = df_final['EMISION'].apply(classify_emision)
        total_titulos = df_final['TITULOS'].sum()
        messagebox.showinfo("Total", f"Suma total de t√≠tulos (neto): {total_titulos:,}")



import requests
import pandas as pd

def alpha_vantage_datos(symbol="IBM"):
    """
    Alpha Vantage - FUNCIONA con API key demo
    """
    try:
        url = "https://www.alphavantage.co/query"
        params = {
            'function': 'TIME_SERIES_DAILY',
            'symbol': symbol,
            'apikey': 'demo',  # Key demo que S√ç funciona
            'outputsize': 'compact'  # 'compact' = √∫ltimos 100 d√≠as
        }
        
        print(f"üì° Obteniendo datos de {symbol} desde Alpha Vantage...")
        response = requests.get(url, params=params, timeout=10)
        data = response.json()
        
        print(f"‚úÖ Status: {response.status_code}")
        print(f"üìä Estructura: {list(data.keys())}")
        
        if "Time Series (Daily)" in data:
            time_series = data["Time Series (Daily)"]
            df = pd.DataFrame.from_dict(time_series, orient='index')
            
            # Convertir tipos de datos
            df = df.astype(float)
            df.columns = ['open', 'high', 'low', 'close', 'volume']
            df.index = pd.to_datetime(df.index)
            
            # Ordenar por fecha (m√°s reciente primero)
            df = df.sort_index(ascending=False)
            
            print(f"‚úÖ {symbol}: {len(df)} registros obtenidos")
            return df
            
        else:
            print("‚ùå No se encontraron datos diarios")
            if "Error Message" in data:
                print(f"Error: {data['Error Message']}")
            if "Note" in data:
                print(f"Nota: {data['Note'][:100]}...")
            return None
            
    except Exception as e:
        print(f"üí• Error: {e}")
        return None

# Probar Alpha Vantage
df_ibm = alpha_vantage_datos("IBM")
if df_ibm is not None:
    print("\nüìà Datos de IBM (primeras 5 filas):")
    print(df_ibm.head())
